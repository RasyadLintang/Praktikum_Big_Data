{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff02e1c-96c3-42e8-8db7-16f5df8b1f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/07 17:07:53 WARN Utils: Your hostname, rasyad-VirtualBox, resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/12/07 17:07:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/07 17:08:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/07 17:08:13 WARN Instrumentation: [cc30080e] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/12/07 17:08:15 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/12/07 17:08:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.9999999999999992]\n",
      "Intercept: 15.000000000000009\n"
     ]
    }
   ],
   "source": [
    "# Example: Linear Regression with Spark MLlib\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
    "\n",
    "# Load sample data\n",
    "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
    "columns = ['ID', 'Feature', 'Target']\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Prepare data for modeling\n",
    "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
    "df_transformed = assembler.transform(df)\n",
    "\n",
    "# Train a linear regression model\n",
    "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
    "model = lr.fit(df_transformed)\n",
    "\n",
    "# Print model coefficients\n",
    "print(f'Coefficients: {model.coefficients}')\n",
    "print(f'Intercept: {model.intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f0235a-8654-4a99-bf61-5b20d93296b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/07 17:10:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-12.262057929987803,4.087352266753044]\n",
      "Intercept: 11.568912727474402\n"
     ]
    }
   ],
   "source": [
    "# Practice: Logistic Regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName('Logistic Reggression').getOrCreate()\n",
    "\n",
    "# Example dataset\n",
    "data = [(1, [2.0, 3.0], 0), (2, [1.0, 5.0], 1), (3, [2.5, 4.5], 1), (4, [3.0, 6.0], 0)]\n",
    "columns = ['ID', 'Features', 'Label']\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Instead of using 'Features' directly, we need to access the elements within the array\n",
    "# Create new columns for 'Features[0]' and 'Features[1]' using Spark functions\n",
    "df = df.withColumn('Feature0', col('Features').getItem(0)) \\\n",
    "       .withColumn('Feature1', col('Features').getItem(1))\n",
    "\n",
    "# Now use VectorAssembler with the new columns\n",
    "assembler = VectorAssembler(inputCols=['Feature0', 'Feature1'], outputCol='FeaturesVector')\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Train logistic regression model using the 'FeaturesVector' column\n",
    "lr = LogisticRegression(featuresCol='FeaturesVector', labelCol='Label')\n",
    "model = lr.fit(df)\n",
    "\n",
    "# Display coefficients and summary\n",
    "print(f'Coefficients: {model.coefficients}')\n",
    "print(f'Intercept: {model.intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf27d12-91f9-461b-b61b-7b7553494c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: [array([5.33333333]), array([15.])]\n"
     ]
    }
   ],
   "source": [
    "# Practice: KMeans Clustering\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Example dataset\n",
    "data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n",
    "columns = ['ID', 'Features']\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df = df.withColumn('Feature1', col('Features').getItem(0))\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['Feature1'], outputCol='Features_vec')\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Train KMeans clustering model\n",
    "kmeans = KMeans(featuresCol='Features_vec', k=2)\n",
    "model = kmeans.fit(df)\n",
    "\n",
    "# Show cluster centers\n",
    "centers = model.clusterCenters()\n",
    "print(f'Cluster Centers: {centers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d516c105-7a1d-48bb-9424-2bd0bda94e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Model Random Forest\n",
      "Test Set Accuracy: 0.4583\n",
      "\n",
      "Model Parameter Terbaik:\n",
      "  - n_estimators: 100\n",
      "  - max_depth: 10\n",
      "\n",
      "Classification Report (Accuracy per class):\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     Commercial       1.00      0.33      0.50         3\n",
      "       Compacts       0.00      0.00      0.00         3\n",
      "         Coupes       0.00      0.00      0.00         5\n",
      "         Cycles       0.00      0.00      0.00         1\n",
      "      Emergency       0.00      0.00      0.00         2\n",
      "     Industrial       0.00      0.00      0.00         2\n",
      "       Military       1.00      0.40      0.57         5\n",
      "    Motorcycles       0.38      0.89      0.53         9\n",
      "         Muscle       1.00      0.31      0.48        16\n",
      "       Off-Road       0.50      0.62      0.55        13\n",
      "     Open Wheel       0.00      0.00      0.00         1\n",
      "           SUVs       0.80      0.57      0.67         7\n",
      "         Sedans       0.56      0.83      0.67         6\n",
      "        Service       0.00      0.00      0.00         1\n",
      "         Sports       0.29      0.60      0.39        20\n",
      "Sports Classics       0.67      0.20      0.31        10\n",
      "          Super       0.60      0.43      0.50         7\n",
      "        Utility       1.00      0.60      0.75         5\n",
      "           Vans       0.22      0.50      0.31         4\n",
      "\n",
      "       accuracy                           0.46       120\n",
      "      macro avg       0.42      0.33      0.33       120\n",
      "   weighted avg       0.55      0.46      0.43       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier # Algoritma Klasifikasi yang Lebih Kuat\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "\n",
    "df = pd.read_csv(\"gta_cars.csv\")\n",
    "\n",
    "df['Price_Clean_Str'] = df['Price'].astype(str).str.split('#').str[0]\n",
    "df['Price_Clean_Str'] = df['Price_Clean_Str'].str.replace('[^0-9,]', '', regex=True)\n",
    "df['Price_Clean_Str'] = df['Price_Clean_Str'].str.replace(',', '')\n",
    "df['Price_Numeric'] = df['Price_Clean_Str'].replace('', np.nan).astype(float)\n",
    "df['Capacity_Numeric'] = df['Capacity'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Ganti nama kolom kelas kendaraan\n",
    "df.rename(columns={'Vehicle class(GTA V/GTA Online)': 'Vehicle_Class'}, inplace=True)\n",
    "\n",
    "# Menjatuhkan baris dengan nilai hilang (juga di 'Body style')\n",
    "df_clean = df.dropna(subset=['Price_Numeric', 'Capacity_Numeric', 'Vehicle_Class', 'Body style']).copy()\n",
    "\n",
    "# Encoding Variabel Target (y)\n",
    "le = LabelEncoder()\n",
    "df_clean['label'] = le.fit_transform(df_clean['Vehicle_Class'])\n",
    "\n",
    "# Tentukan Fitur BARU (X) dan Target (y)\n",
    "feature_cols = ['Price_Numeric', 'Capacity_Numeric', 'Body style'] # Tambah Body style\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean['label']\n",
    "target_names = le.classes_\n",
    "\n",
    "# Split data (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build Pipeline dengan Feature Engineering Lanjutan \n",
    "\n",
    "numeric_features = ['Price_Numeric', 'Capacity_Numeric']\n",
    "categorical_features = ['Body style'] # Fitur baru\n",
    "\n",
    "#  Standardisasi untuk numerik, One-Hot Encoding untuk kategorikal\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        # One-Hot Encoding untuk Body style\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Pipeline: Preprocessing -> Random Forest Classifier (Lebih Kuat)\n",
    "# RandomForest tidak memerlukan regulasi (C atau penalty) seperti Logistic Regression\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', rf)])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100], # Jumlah trees\n",
    "    'classifier__max_depth': [5, 10] # Kedalaman \n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    cv_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    cv_model_rf = cv_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi Model Random Forest\n",
    "y_pred_rf = cv_model_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Menangani masalah mismatch kelas\n",
    "unique_labels_rf = np.unique(np.concatenate([y_test, y_pred_rf]))\n",
    "filtered_target_names_rf = [target_names[i] for i in unique_labels_rf]\n",
    "\n",
    "print(\"Hasil Model Random Forest\")\n",
    "print(f\"Test Set Accuracy: {accuracy_rf:.4f}\")\n",
    "print(\"\\nModel Parameter Terbaik:\")\n",
    "print(f\"  - n_estimators: {cv_model_rf.best_params_['classifier__n_estimators']}\")\n",
    "print(f\"  - max_depth: {cv_model_rf.best_params_['classifier__max_depth']}\")\n",
    "\n",
    "print(\"\\nClassification Report (Accuracy per class):\")\n",
    "print(classification_report(y_test, y_pred_rf, labels=unique_labels_rf, target_names=filtered_target_names_rf, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
